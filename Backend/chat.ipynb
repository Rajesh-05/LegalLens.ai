{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2529ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vertexai\n",
      "  Downloading vertexai-1.71.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-aiplatform==1.71.1 (from google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.40.3)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\rajesh akaike\\appdata\\roaming\\python\\python313\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (25.0)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading google_cloud_bigquery-3.37.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading google_cloud_resource_manager-1.14.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading shapely-2.1.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.11.7)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.74.0)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.9.1)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\rajesh akaike\\appdata\\roaming\\python\\python313\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading grpc_google_iam_v1-0.14.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading google_crc32c-1.7.1-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rajesh akaike\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\rajesh akaike\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.2.0)\n",
      "Downloading vertexai-1.71.1-py3-none-any.whl (7.3 kB)\n",
      "Downloading google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.2 MB 3.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.3/6.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.7/6.2 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_cloud_bigquery-3.37.0-py3-none-any.whl (258 kB)\n",
      "Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_resource_manager-1.14.2-py3-none-any.whl (394 kB)\n",
      "Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Downloading google_crc32c-1.7.1-cp313-cp313-win_amd64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading shapely-2.1.1-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 9.7 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely, protobuf, google-crc32c, docstring-parser, proto-plus, googleapis-common-protos, google-resumable-media, grpcio-status, google-api-core, grpc-google-iam-v1, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform, vertexai\n",
      "\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "  Attempting uninstall: protobuf\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "    Found existing installation: protobuf 6.32.0\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "    Uninstalling protobuf-6.32.0:\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "      Successfully uninstalled protobuf-6.32.0\n",
      "   ----------------------------------------  0/16 [shapely]\n",
      "   -- -------------------------------------  1/16 [protobuf]\n",
      "   -- -------------------------------------  1/16 [protobuf]\n",
      "   -- -------------------------------------  1/16 [protobuf]\n",
      "   -- -------------------------------------  1/16 [protobuf]\n",
      "   -- -------------------------------------  1/16 [protobuf]\n",
      "   -- -------------------------------------  1/16 [protobuf]\n",
      "   ----- ----------------------------------  2/16 [google-crc32c]\n",
      "   ------- --------------------------------  3/16 [docstring-parser]\n",
      "   ---------- -----------------------------  4/16 [proto-plus]\n",
      "   ---------- -----------------------------  4/16 [proto-plus]\n",
      "   ------------ ---------------------------  5/16 [googleapis-common-protos]\n",
      "   ------------ ---------------------------  5/16 [googleapis-common-protos]\n",
      "   ------------ ---------------------------  5/16 [googleapis-common-protos]\n",
      "   ------------ ---------------------------  5/16 [googleapis-common-protos]\n",
      "   ------------ ---------------------------  5/16 [googleapis-common-protos]\n",
      "   ------------ ---------------------------  5/16 [googleapis-common-protos]\n",
      "   ------------ ---------------------------  5/16 [googleapis-common-protos]\n",
      "   ------------ ---------------------------  5/16 [googleapis-common-protos]\n",
      "   --------------- ------------------------  6/16 [google-resumable-media]\n",
      "   --------------- ------------------------  6/16 [google-resumable-media]\n",
      "   -------------------- -------------------  8/16 [google-api-core]\n",
      "   -------------------- -------------------  8/16 [google-api-core]\n",
      "   -------------------- -------------------  8/16 [google-api-core]\n",
      "   -------------------- -------------------  8/16 [google-api-core]\n",
      "   -------------------- -------------------  8/16 [google-api-core]\n",
      "   ---------------------- -----------------  9/16 [grpc-google-iam-v1]\n",
      "   ------------------------- -------------- 10/16 [google-cloud-core]\n",
      "   --------------------------- ------------ 11/16 [google-cloud-storage]\n",
      "   --------------------------- ------------ 11/16 [google-cloud-storage]\n",
      "   ---------------------------- --------- 12/16 [google-cloud-resource-manager]\n",
      "   ---------------------------- --------- 12/16 [google-cloud-resource-manager]\n",
      "   ---------------------------- --------- 12/16 [google-cloud-resource-manager]\n",
      "   ---------------------------- --------- 12/16 [google-cloud-resource-manager]\n",
      "   ---------------------------- --------- 12/16 [google-cloud-resource-manager]\n",
      "   ---------------------------- --------- 12/16 [google-cloud-resource-manager]\n",
      "   ---------------------------- --------- 12/16 [google-cloud-resource-manager]\n",
      "   ---------------------------- --------- 12/16 [google-cloud-resource-manager]\n",
      "   -------------------------------- ------- 13/16 [google-cloud-bigquery]\n",
      "   -------------------------------- ------- 13/16 [google-cloud-bigquery]\n",
      "   -------------------------------- ------- 13/16 [google-cloud-bigquery]\n",
      "   -------------------------------- ------- 13/16 [google-cloud-bigquery]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ----------------------------------- ---- 14/16 [google-cloud-aiplatform]\n",
      "   ------------------------------------- -- 15/16 [vertexai]\n",
      "   ---------------------------------------- 16/16 [vertexai]\n",
      "\n",
      "Successfully installed docstring-parser-0.17.0 google-api-core-2.25.1 google-cloud-aiplatform-1.71.1 google-cloud-bigquery-3.37.0 google-cloud-core-2.4.3 google-cloud-resource-manager-1.14.2 google-cloud-storage-2.19.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 grpc-google-iam-v1-0.14.2 grpcio-status-1.71.2 proto-plus-1.26.1 protobuf-5.29.5 shapely-2.1.1 vertexai-1.71.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google import genai\n",
    "from google.genai.generative import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8330103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=\"AIzaSyAZLY9vmRdQCpODSnpzF_BA3iXTmbJ2y6A\")\n",
    "\n",
    "grounding_tool = types.Tool(\n",
    "    google_search=types.GoogleSearch()\n",
    ")\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[grounding_tool]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a53a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "model=\"gemini-2.5-flash\",\n",
    "contents=\"What is the gold rate today?\",\n",
    "config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59eb3e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of September 16, 2025, gold rates show some variation depending on purity and location.\\n\\nIn India, the gold rates per gram are as follows:\\n*   **24 Carat Gold:** ₹11,193 (Indian Rupees)\\n*   **22 Carat Gold:** ₹10,260 (Indian Rupees)\\n*   **18 Carat Gold:** ₹8,395 (Indian Rupees)\\n\\nThese rates reflect a slight increase from the previous day, with 24K gold rising by ₹87, 22K gold by ₹80, and 18K gold by ₹66 per gram. For example, in Chennai, 24K gold is ₹11,215 per gram and 22K gold is ₹10,280 per gram. The upcoming festive season in India is expected to boost demand for gold and silver jewelry, potentially leading to further price increases.\\n\\nGlobally, the live spot price of gold is approximately:\\n*   **Per Ounce:** $3,678.00 USD\\n*   **Per Gram:** $118.90 USD\\n\\nGold prices are subject to constant change due to various factors including international market prices, currency exchange rates, and demand-supply dynamics.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f67f1a02",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Manual function declaration\u001b[39;00m\n\u001b[32m     17\u001b[39m get_current_weather_func = FunctionDeclaration(\n\u001b[32m     18\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mget_current_weather\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mGet the current weather in a given location\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     },\n\u001b[32m     33\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m      \u001b[49m\u001b[43mContent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m          \u001b[49m\u001b[43mparts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m              \u001b[49m\u001b[43mPart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_text\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the weather like in Chennai?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m          \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mGenerationConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m      \u001b[49m\u001b[43mTool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunction_declarations\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_current_weather_func\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:654\u001b[39m, in \u001b[36m_GenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[39m\n\u001b[32m    645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content_streaming(\n\u001b[32m    646\u001b[39m         contents=contents,\n\u001b[32m    647\u001b[39m         generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    651\u001b[39m         labels=labels,\n\u001b[32m    652\u001b[39m     )\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:779\u001b[39m, in \u001b[36m_GenerativeModel._generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[39m\n\u001b[32m    752\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[32m    753\u001b[39m \n\u001b[32m    754\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    769\u001b[39m \u001b[33;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[32m    770\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    771\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m    772\u001b[39m     contents=contents,\n\u001b[32m    773\u001b[39m     generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    777\u001b[39m     labels=labels,\n\u001b[32m    778\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m gapic_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prediction_client\u001b[49m.generate_content(request=request)\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_response(gapic_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\vertexai\\generative_models\\_generative_models.py:3138\u001b[39m, in \u001b[36mGenerativeModel._prediction_client\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3133\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   3134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prediction_client\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> prediction_service_v1.PredictionServiceClient:\n\u001b[32m   3135\u001b[39m     \u001b[38;5;66;03m# Switch to @functools.cached_property once its available.\u001b[39;00m\n\u001b[32m   3136\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_prediction_client_value\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   3137\u001b[39m         \u001b[38;5;28mself\u001b[39m._prediction_client_value = (\n\u001b[32m-> \u001b[39m\u001b[32m3138\u001b[39m             \u001b[43maiplatform_initializer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglobal_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3139\u001b[39m \u001b[43m                \u001b[49m\u001b[43mclient_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprediction_service_v1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPredictionServiceClient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3140\u001b[39m \u001b[43m                \u001b[49m\u001b[43mlocation_override\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3141\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprediction_client\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3142\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3143\u001b[39m         )\n\u001b[32m   3144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prediction_client_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\cloud\\aiplatform\\initializer.py:622\u001b[39m, in \u001b[36m_Config.create_client\u001b[39m\u001b[34m(self, client_class, credentials, location_override, prediction_client, api_base_path_override, api_key, api_path_override, appended_user_agent, appended_gapic_version)\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_transport == \u001b[33m\"\u001b[39m\u001b[33mrest\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    619\u001b[39m     \u001b[38;5;66;03m# User requests sync REST\u001b[39;00m\n\u001b[32m    620\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtransport\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._api_transport\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m client = \u001b[43mclient_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[38;5;66;03m# We only wrap the client if the request_metadata is set at the creation time.\u001b[39;00m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_metadata:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\client.py:744\u001b[39m, in \u001b[36mPredictionServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    739\u001b[39m     credentials = google.auth._default.get_api_key_credentials(\n\u001b[32m    740\u001b[39m         api_key_value\n\u001b[32m    741\u001b[39m     )\n\u001b[32m    743\u001b[39m \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\transports\\rest.py:651\u001b[39m, in \u001b[36mPredictionServiceRestTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, url_scheme, interceptor, api_audience)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Instantiate the transport.\u001b[39;00m\n\u001b[32m    616\u001b[39m \n\u001b[32m    617\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m \u001b[33;03m        \"http\" can be specified.\u001b[39;00m\n\u001b[32m    646\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    647\u001b[39m \u001b[38;5;66;03m# Run the base constructor\u001b[39;00m\n\u001b[32m    648\u001b[39m \u001b[38;5;66;03m# TODO(yon-mg): resolve other ctor params i.e. scopes, quota, etc.\u001b[39;00m\n\u001b[32m    649\u001b[39m \u001b[38;5;66;03m# TODO: When custom host (api_endpoint) is set, `scopes` must *also* be set on the\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[38;5;66;03m# credentials object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl_scheme\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_scheme\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[38;5;28mself\u001b[39m._session = AuthorizedSession(\n\u001b[32m    660\u001b[39m     \u001b[38;5;28mself\u001b[39m._credentials, default_host=\u001b[38;5;28mself\u001b[39m.DEFAULT_HOST\n\u001b[32m    661\u001b[39m )\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m client_cert_source_for_mtls:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\transports\\rest_base.py:89\u001b[39m, in \u001b[36m_BasePredictionServiceRestTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, client_info, always_use_jwt_access, url_scheme, api_audience)\u001b[39m\n\u001b[32m     85\u001b[39m url_match_items = maybe_url_match.groupdict()\n\u001b[32m     87\u001b[39m host = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_scheme\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url_match_items[\u001b[33m\"\u001b[39m\u001b[33mscheme\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m host\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\transports\\base.py:108\u001b[39m, in \u001b[36mPredictionServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m    104\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m    105\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m    106\u001b[39m     )\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rajesh Akaike\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\auth\\_default.py:685\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    677\u001b[39m             _LOGGER.warning(\n\u001b[32m    678\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    679\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    680\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    681\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    682\u001b[39m             )\n\u001b[32m    683\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    "    ToolConfig\n",
    ")\n",
    "\n",
    "vertexai.init(api_key=\"AIzaSyAZLY9vmRdQCpODSnpzF_BA3iXTmbJ2y6A\")\n",
    "# Initialize Gemini model\n",
    "model = GenerativeModel(model_name=\"gemini-2.0-flash\",)\n",
    "\n",
    "# Manual function declaration\n",
    "get_current_weather_func = FunctionDeclaration(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"Get the current weather in a given location\",\n",
    "    # Function parameters are specified in JSON schema format\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city name of the location for which to get the weather.\",\n",
    "              \"default\": {\n",
    "                \"string_value\": \"Boston, MA\"\n",
    "              }\n",
    "           }\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "response = model.generate_content(\n",
    "    contents = [\n",
    "      Content(\n",
    "        role=\"user\",\n",
    "          parts=[\n",
    "              Part.from_text(\"What is the weather like in Chennai?\"),\n",
    "          ],\n",
    "      )\n",
    "    ],\n",
    "    generation_config = GenerationConfig(temperature=0),\n",
    "    tools = [\n",
    "      Tool(\n",
    "        function_declarations=[get_current_weather_func],\n",
    "      )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Optional, TypedDict, Annotated\n",
    "import json\n",
    "from langgraph.graph import StateGraph, END\n",
    "# from langgraph.prebuilt import ToolExecutor\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Optional, TypedDict, Annotated\n",
    "import json\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import operator\n",
    "\n",
    "# Initialize Gemini client\n",
    "client = genai.Client(api_key=\"AIzaSyAZLY9vmRdQCpODSnpzF_BA3iXTmbJ2y6A\")\n",
    "\n",
    "# Tool Definitions using Gemini function declarations\n",
    "def get_summary_function():\n",
    "    return {\n",
    "        \"name\": \"get_summary\",\n",
    "        \"description\": \"Get the AIS summary from memory\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "def get_relevant_data_function():\n",
    "    return {\n",
    "        \"name\": \"get_relevant_data\",\n",
    "        \"description\": \"Get relevant transaction data from vector DB based on query\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Query to search for relevant transaction data\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "def get_question_function():\n",
    "    return {\n",
    "        \"name\": \"get_question\",\n",
    "        \"description\": \"Get the next question to ask the user about income sources\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "def get_schema_function():\n",
    "    return {\n",
    "        \"name\": \"get_schema\",\n",
    "        \"description\": \"Get the schema for a particular field in ITR JSON\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"field_type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Type of income field (salary, interest, dividend, etc.)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"field_type\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "def update_json_function():\n",
    "    return {\n",
    "        \"name\": \"update_json\",\n",
    "        \"description\": \"Update the ITR JSON with collected data\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"data\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Data to be updated in JSON format\"\n",
    "                },\n",
    "                \"section\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Section of ITR to update\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"data\", \"section\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Tool execution functions\n",
    "def execute_get_summary():\n",
    "    \"\"\"Get the AIS summary from memory.\"\"\"\n",
    "    return \"AIS Summary: Contains salary income, interest income, and dividend income for FY 2023-24\"\n",
    "\n",
    "def execute_get_relevant_data(query: str):\n",
    "    \"\"\"Get relevant transaction data from vector DB based on query.\"\"\"\n",
    "    sample_data = {\n",
    "        \"salary\": \"Annual salary: ₹12,00,000, TDS: ₹1,20,000\",\n",
    "        \"interest\": \"Bank interest: ₹45,000 from SBI, ₹23,000 from HDFC\",\n",
    "        \"dividend\": \"Dividend income: ₹15,000 from mutual funds\"\n",
    "    }\n",
    "    \n",
    "    for key, value in sample_data.items():\n",
    "        if key.lower() in query.lower():\n",
    "            return value\n",
    "    return \"No relevant data found for the query\"\n",
    "\n",
    "def execute_get_question():\n",
    "    \"\"\"Get the next question to ask the user about income sources.\"\"\"\n",
    "    questions = [\n",
    "        \"Do you have salary income?\",\n",
    "        \"Do you have interest income from banks?\",\n",
    "        \"Do you have dividend income?\",\n",
    "        \"Do you have rental income?\",\n",
    "        \"Do you have capital gains?\",\n",
    "        \"Do you have business income?\"\n",
    "    ]\n",
    "    return questions[0]  # Simplified for demo\n",
    "\n",
    "def execute_get_schema(field_type: str):\n",
    "    \"\"\"Get the schema for a particular field in ITR JSON.\"\"\"\n",
    "    schemas = {\n",
    "        \"salary\": {\n",
    "            \"required_fields\": [\"employer_name\", \"annual_salary\", \"tds_deducted\", \"pan_of_employer\"],\n",
    "            \"field_types\": {\n",
    "                \"employer_name\": \"string\",\n",
    "                \"annual_salary\": \"number\",\n",
    "                \"tds_deducted\": \"number\",\n",
    "                \"pan_of_employer\": \"string\"\n",
    "            },\n",
    "            \"validations\": {\n",
    "                \"annual_salary\": \"Must be positive number\",\n",
    "                \"tds_deducted\": \"Must be less than or equal to annual_salary\",\n",
    "                \"pan_of_employer\": \"Must be valid PAN format\"\n",
    "            }\n",
    "        },\n",
    "        \"interest\": {\n",
    "            \"required_fields\": [\"bank_name\", \"interest_amount\", \"tds_deducted\"],\n",
    "            \"field_types\": {\n",
    "                \"bank_name\": \"string\",\n",
    "                \"interest_amount\": \"number\",\n",
    "                \"tds_deducted\": \"number\"\n",
    "            }\n",
    "        },\n",
    "        \"dividend\": {\n",
    "            \"required_fields\": [\"company_name\", \"dividend_amount\", \"tds_deducted\"],\n",
    "            \"field_types\": {\n",
    "                \"company_name\": \"string\",\n",
    "                \"dividend_amount\": \"number\",\n",
    "                \"tds_deducted\": \"number\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return schemas.get(field_type, {})\n",
    "\n",
    "def execute_update_json(data: Dict[str, Any], section: str):\n",
    "    \"\"\"Update the ITR JSON with collected data.\"\"\"\n",
    "    print(f\"Updating {section} section with data: {json.dumps(data, indent=2)}\")\n",
    "    return f\"Successfully updated {section} section in ITR JSON\"\n",
    "\n",
    "# Function to execute tools\n",
    "def execute_function_call(function_name: str, arguments: Dict[str, Any]):\n",
    "    \"\"\"Execute the appropriate function based on function name and arguments.\"\"\"\n",
    "    if function_name == \"get_summary\":\n",
    "        return execute_get_summary()\n",
    "    elif function_name == \"get_relevant_data\":\n",
    "        return execute_get_relevant_data(arguments.get(\"query\", \"\"))\n",
    "    elif function_name == \"get_question\":\n",
    "        return execute_get_question()\n",
    "    elif function_name == \"get_schema\":\n",
    "        return execute_get_schema(arguments.get(\"field_type\", \"\"))\n",
    "    elif function_name == \"update_json\":\n",
    "        return execute_update_json(arguments.get(\"data\", {}), arguments.get(\"section\", \"\"))\n",
    "    else:\n",
    "        return f\"Unknown function: {function_name}\"\n",
    "\n",
    "# State Definition\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    ais_summary: str\n",
    "    ais_data: str\n",
    "    current_question: Optional[str]\n",
    "    current_schema: Optional[Dict[str, Any]]\n",
    "    collected_data: Dict[str, Any]\n",
    "    pending_fields: List[str]\n",
    "    itr_json: Dict[str, Any]\n",
    "    next_action: str\n",
    "    user_response: Optional[str]\n",
    "    question_answered: bool\n",
    "    data_complete: bool\n",
    "    conversation_history: List[str]\n",
    "\n",
    "# Gemini Model Integration\n",
    "class GeminiTaxAgent:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        self.config = types.GenerateContentConfig(\n",
    "            system_instruction=\"\"\"You are an AI assistant for Income Tax Filing. Your role is to:\n",
    "            1. Ask users about different income sources systematically\n",
    "            2. When user confirms having an income source, get the schema and collect all required details\n",
    "            3. Validate that all required fields are provided before updating the JSON\n",
    "            4. Use the available tools to get questions, schemas, and update data\n",
    "            5. Be helpful and clear in your communication with users\n",
    "            6. Ensure data completeness before moving to next income source\n",
    "            \n",
    "            Use the tools whenever necessary to accomplish these tasks.\"\"\",\n",
    "            tools=[\n",
    "                types.Tool(function_declarations=[\n",
    "                    get_summary_function(),\n",
    "                    get_relevant_data_function(), \n",
    "                    get_question_function(),\n",
    "                    get_schema_function(),\n",
    "                    update_json_function()\n",
    "                ])\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def generate_response(self, prompt: str, conversation_history: List[str] = None) -> str:\n",
    "        \"\"\"Generate response using Gemini model with tools.\"\"\"\n",
    "        try:\n",
    "            # Include conversation history in prompt if available\n",
    "            full_prompt = prompt\n",
    "            if conversation_history:\n",
    "                context = \"\\n\".join(conversation_history[-10:])  # Last 10 messages\n",
    "                full_prompt = f\"Conversation History:\\n{context}\\n\\nCurrent Query: {prompt}\"\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                contents=full_prompt,\n",
    "                config=self.config\n",
    "            )\n",
    "            \n",
    "            # Handle function calls if present\n",
    "            if hasattr(response, 'candidates') and response.candidates:\n",
    "                candidate = response.candidates[0]\n",
    "                \n",
    "                # Check for function calls\n",
    "                if hasattr(candidate, 'content') and candidate.content.parts:\n",
    "                    for part in candidate.content.parts:\n",
    "                        if hasattr(part, 'function_call'):\n",
    "                            # Execute function call\n",
    "                            function_name = part.function_call.name\n",
    "                            function_args = dict(part.function_call.args) if part.function_call.args else {}\n",
    "                            \n",
    "                            # Execute the function\n",
    "                            function_result = execute_function_call(function_name, function_args)\n",
    "                            \n",
    "                            # Return function result with context\n",
    "                            return f\"[Function: {function_name}] {function_result}\"\n",
    "                \n",
    "                # Return regular text response\n",
    "                if hasattr(candidate.content, 'parts') and candidate.content.parts:\n",
    "                    return candidate.content.parts[0].text\n",
    "                \n",
    "            return \"I apologize, but I couldn't generate a proper response. Please try again.\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "# Node Functions\n",
    "def ask_question_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Node that asks the user a question about income sources.\"\"\"\n",
    "    agent = GeminiTaxAgent(api_key=\"your-api-key-here\")  # Replace with actual API key\n",
    "    \n",
    "    if not state.get(\"current_question\"):\n",
    "        # Get next question using Gemini\n",
    "        response = agent.generate_response(\n",
    "            \"Get the next question to ask about income sources using get_question tool\",\n",
    "            state.get(\"conversation_history\", [])\n",
    "        )\n",
    "        \n",
    "        # Extract question from response\n",
    "        if \"[Function: get_question]\" in response:\n",
    "            question = response.split(\"[Function: get_question]\")[-1].strip()\n",
    "            state[\"current_question\"] = question\n",
    "        else:\n",
    "            state[\"current_question\"] = response\n",
    "    \n",
    "    # Create AI message with the question\n",
    "    ai_message = AIMessage(content=state[\"current_question\"])\n",
    "    state[\"messages\"] = [ai_message]\n",
    "    state[\"next_action\"] = \"wait_for_user_response\"\n",
    "    \n",
    "    # Update conversation history\n",
    "    if \"conversation_history\" not in state:\n",
    "        state[\"conversation_history\"] = []\n",
    "    state[\"conversation_history\"].append(f\"Agent: {state['current_question']}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def process_user_response_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Process the user's response to the question.\"\"\"\n",
    "    agent = GeminiTaxAgent(api_key=\"your-api-key-here\")  # Replace with actual API key\n",
    "    \n",
    "    if not state[\"messages\"]:\n",
    "        return state\n",
    "    \n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        user_response = last_message.content\n",
    "        \n",
    "        # Update conversation history\n",
    "        state[\"conversation_history\"].append(f\"User: {user_response}\")\n",
    "        \n",
    "        # Use Gemini to analyze user response\n",
    "        prompt = f\"User responded: '{user_response}' to the question: '{state.get('current_question', '')}'. Determine if this is a positive response (yes/y/true) or negative (no/n/false). Respond with just 'YES' or 'NO'.\"\n",
    "        \n",
    "        analysis = agent.generate_response(prompt, state.get(\"conversation_history\", []))\n",
    "        \n",
    "        if \"YES\" in analysis.upper():\n",
    "            state[\"question_answered\"] = True\n",
    "            state[\"next_action\"] = \"get_schema\"\n",
    "        else:\n",
    "            # Move to next question\n",
    "            state[\"question_answered\"] = False\n",
    "            state[\"current_question\"] = None\n",
    "            state[\"next_action\"] = \"ask_question\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def get_schema_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Get the schema for the current income type.\"\"\"\n",
    "    agent = GeminiTaxAgent(api_key=\"your-api-key-here\")  # Replace with actual API key\n",
    "    \n",
    "    current_question = state.get(\"current_question\", \"\")\n",
    "    \n",
    "    # Use Gemini to determine income type from question\n",
    "    prompt = f\"Based on this question: '{current_question}', determine the income type (salary, interest, dividend, rental, capital_gains, business). Respond with just the income type.\"\n",
    "    \n",
    "    income_type_response = agent.generate_response(prompt, state.get(\"conversation_history\", []))\n",
    "    income_type = income_type_response.strip().lower()\n",
    "    \n",
    "    # Get schema using the tool\n",
    "    schema_prompt = f\"Get the schema for {income_type} using get_schema tool\"\n",
    "    schema_response = agent.generate_response(schema_prompt, state.get(\"conversation_history\", []))\n",
    "    \n",
    "    if \"[Function: get_schema]\" in schema_response:\n",
    "        # Extract schema from response (in practice, you'd parse the JSON properly)\n",
    "        schema = execute_get_schema(income_type)\n",
    "        state[\"current_schema\"] = schema\n",
    "        state[\"pending_fields\"] = schema.get(\"required_fields\", [])\n",
    "        state[\"collected_data\"] = {}\n",
    "        state[\"next_action\"] = \"collect_data\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def collect_data_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Collect data from user based on schema.\"\"\"\n",
    "    agent = GeminiTaxAgent(api_key=\"your-api-key-here\")  # Replace with actual API key\n",
    "    \n",
    "    schema = state.get(\"current_schema\", {})\n",
    "    pending_fields = state.get(\"pending_fields\", [])\n",
    "    \n",
    "    if not pending_fields:\n",
    "        state[\"data_complete\"] = True\n",
    "        state[\"next_action\"] = \"update_json\"\n",
    "        return state\n",
    "    \n",
    "    # Ask for the next required field\n",
    "    current_field = pending_fields[0]\n",
    "    field_type = schema.get(\"field_types\", {}).get(current_field, \"string\")\n",
    "    validation = schema.get(\"validations\", {}).get(current_field, \"\")\n",
    "    \n",
    "    prompt = f\"Please provide {current_field.replace('_', ' ')} ({field_type})\"\n",
    "    if validation:\n",
    "        prompt += f\". Note: {validation}\"\n",
    "    \n",
    "    ai_message = AIMessage(content=prompt)\n",
    "    state[\"messages\"] = [ai_message]\n",
    "    state[\"next_action\"] = \"process_field_input\"\n",
    "    \n",
    "    # Update conversation history\n",
    "    state[\"conversation_history\"].append(f\"Agent: {prompt}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def process_field_input_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Process user input for a specific field.\"\"\"\n",
    "    agent = GeminiTaxAgent(api_key=\"your-api-key-here\")  # Replace with actual API key\n",
    "    \n",
    "    if not state[\"messages\"]:\n",
    "        return state\n",
    "    \n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        user_input = last_message.content.strip()\n",
    "        pending_fields = state.get(\"pending_fields\", [])\n",
    "        \n",
    "        # Update conversation history\n",
    "        state[\"conversation_history\"].append(f\"User: {user_input}\")\n",
    "        \n",
    "        if pending_fields:\n",
    "            current_field = pending_fields[0]\n",
    "            \n",
    "            # Use Gemini to validate input\n",
    "            validation_prompt = f\"Validate if '{user_input}' is appropriate for field '{current_field}'. Respond with 'VALID' or 'INVALID' followed by reason.\"\n",
    "            \n",
    "            validation = agent.generate_response(validation_prompt, state.get(\"conversation_history\", []))\n",
    "            \n",
    "            if \"VALID\" in validation.upper():\n",
    "                state[\"collected_data\"][current_field] = user_input\n",
    "                state[\"pending_fields\"] = pending_fields[1:]  # Remove processed field\n",
    "                \n",
    "                if not state[\"pending_fields\"]:\n",
    "                    state[\"data_complete\"] = True\n",
    "                    state[\"next_action\"] = \"update_json\"\n",
    "                else:\n",
    "                    state[\"next_action\"] = \"collect_data\"  # Continue collecting\n",
    "            else:\n",
    "                # Invalid input, ask again\n",
    "                ai_message = AIMessage(content=f\"Invalid input. Please provide a valid {current_field.replace('_', ' ')}\")\n",
    "                state[\"messages\"] = [ai_message]\n",
    "                state[\"conversation_history\"].append(f\"Agent: Invalid input. Please provide a valid {current_field.replace('_', ' ')}\")\n",
    "                state[\"next_action\"] = \"process_field_input\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def update_json_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Update the ITR JSON with collected data.\"\"\"\n",
    "    agent = GeminiTaxAgent(api_key=\"your-api-key-here\")  # Replace with actual API key\n",
    "    \n",
    "    collected_data = state.get(\"collected_data\", {})\n",
    "    current_question = state.get(\"current_question\", \"\")\n",
    "    \n",
    "    # Determine section based on question using Gemini\n",
    "    section_prompt = f\"Based on this question: '{current_question}', determine the ITR section name (salary_income, interest_income, dividend_income, etc.)\"\n",
    "    section_response = agent.generate_response(section_prompt, state.get(\"conversation_history\", []))\n",
    "    section = section_response.strip().lower()\n",
    "    \n",
    "    if collected_data:\n",
    "        # Use update_json tool\n",
    "        update_prompt = f\"Update JSON using update_json tool with data: {json.dumps(collected_data)} for section: {section}\"\n",
    "        result = agent.generate_response(update_prompt, state.get(\"conversation_history\", []))\n",
    "        \n",
    "        # Update ITR JSON in state\n",
    "        if \"itr_json\" not in state:\n",
    "            state[\"itr_json\"] = {}\n",
    "        state[\"itr_json\"][section] = collected_data\n",
    "        \n",
    "        ai_message = AIMessage(content=f\"Data collected and saved for {section}.\")\n",
    "        state[\"messages\"] = [ai_message]\n",
    "        state[\"conversation_history\"].append(f\"Agent: Data collected and saved for {section}.\")\n",
    "    \n",
    "    # Reset for next question\n",
    "    state[\"current_question\"] = None\n",
    "    state[\"current_schema\"] = None\n",
    "    state[\"collected_data\"] = {}\n",
    "    state[\"pending_fields\"] = []\n",
    "    state[\"question_answered\"] = False\n",
    "    state[\"data_complete\"] = False\n",
    "    state[\"next_action\"] = \"ask_question\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determine the next node based on current state.\"\"\"\n",
    "    next_action = state.get(\"next_action\", \"ask_question\")\n",
    "    \n",
    "    if next_action == \"wait_for_user_response\":\n",
    "        return \"process_response\"\n",
    "    elif next_action == \"get_schema\":\n",
    "        return \"get_schema\"\n",
    "    elif next_action == \"collect_data\":\n",
    "        return \"collect_data\"\n",
    "    elif next_action == \"process_field_input\":\n",
    "        return \"process_field_input\"\n",
    "    elif next_action == \"update_json\":\n",
    "        return \"update_json\"\n",
    "    elif next_action == \"ask_question\":\n",
    "        return \"ask_question\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "# Create the graph\n",
    "def create_tax_filing_agent():\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"ask_question\", ask_question_node)\n",
    "    workflow.add_node(\"process_response\", process_user_response_node)\n",
    "    workflow.add_node(\"get_schema\", get_schema_node)\n",
    "    workflow.add_node(\"collect_data\", collect_data_node)\n",
    "    workflow.add_node(\"process_field_input\", process_field_input_node)\n",
    "    workflow.add_node(\"update_json\", update_json_node)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"ask_question\")\n",
    "    \n",
    "    # Add conditional edges\n",
    "    workflow.add_conditional_edges(\n",
    "        \"ask_question\",\n",
    "        should_continue\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"process_response\",\n",
    "        should_continue\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"get_schema\",\n",
    "        should_continue\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"collect_data\",\n",
    "        should_continue\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"process_field_input\",\n",
    "        should_continue\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"update_json\",\n",
    "        should_continue\n",
    "    )\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Usage Example\n",
    "def run_tax_filing_agent(api_key: str):\n",
    "    agent = create_tax_filing_agent()\n",
    "    \n",
    "    # Initial state\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"ais_summary\": \"\",\n",
    "        \"ais_data\": \"\",\n",
    "        \"current_question\": None,\n",
    "        \"current_schema\": None,\n",
    "        \"collected_data\": {},\n",
    "        \"pending_fields\": [],\n",
    "        \"itr_json\": {},\n",
    "        \"next_action\": \"ask_question\",\n",
    "        \"user_response\": None,\n",
    "        \"question_answered\": False,\n",
    "        \"data_complete\": False,\n",
    "        \"conversation_history\": []\n",
    "    }\n",
    "    \n",
    "    # Run the agent\n",
    "    print(\"Tax Filing Agent Started!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    state = initial_state\n",
    "    \n",
    "    while True:\n",
    "        # Execute next step\n",
    "        result = agent.invoke(state)\n",
    "        state = result\n",
    "        \n",
    "        # Display AI message to user\n",
    "        if state.get(\"messages\"):\n",
    "            last_message = state[\"messages\"][-1]\n",
    "            if isinstance(last_message, AIMessage):\n",
    "                print(f\"Agent: {last_message.content}\")\n",
    "                \n",
    "                # Get user input\n",
    "                if state.get(\"next_action\") in [\"wait_for_user_response\", \"process_field_input\"]:\n",
    "                    user_input = input(\"You: \")\n",
    "                    human_message = HumanMessage(content=user_input)\n",
    "                    state[\"messages\"] = [human_message]\n",
    "        \n",
    "        # Check if we should end (you can add your own termination logic)\n",
    "        if len(state.get(\"itr_json\", {})) >= 3:  # Example: stop after collecting 3 income types\n",
    "            print(\"\\nTax filing data collection completed!\")\n",
    "            print(\"Final ITR JSON:\")\n",
    "            print(json.dumps(state[\"itr_json\"], indent=2))\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = \"AIzaSyAZLY9vmRdQCpODSnpzF_BA3iXTmbJ2y6A\"\n",
    "    run_tax_filing_agent(API_KEY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
